---
title: "Distance Sampling Simulations"
subtitle: "Using DSsim to Investigate Truncation Distances with Individual Level Covariates"
author: "Laura Marshall"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{DSsim - Truncation Distances}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## 1. Introduction

Distance Sampling is a process in which a study area is surveyed in order to estimate the size of the population within it. It can be thought of as an extension to plot sampling. However, while plot sampling assumes that all objects within the plots are detected, distance sampling relaxes this assumption. Note fo the purposes of distance sampling an object can either be an individual or a cluster or individuals. Distance sampling makes assumptions about the distribution of objects with respect to the transects which are based on randomly located transects. Then by fitting a detection function to the recorded distances between the objects and the transect they were detected from we can estimate how many objects were missed and hence the total number in the covered area. And example of a detection function is given in Figure 1.  

```{r detection function, warning=FALSE, message=FALSE, echo=FALSE, fig.width = 6, fig.cap="Figure 1: An Example detection function. The histogram shows example distances recorded from a line transect. The smooth curve is the detection function. The grey shaded area represents the number of detected objects and the diagonal hash region represents the number of objects in the covered region that were not detected."}
x <- seq(0, 70, length = 200)
scale <- 25
y <- exp(-x^2/(2*scale^2))

plot(x,y, type = "l", xlab = "Distance", ylab = "Probability of Detection", main = "Example Detection Function")

coords.x <- c(0,x,70,0)
coords.y <- c(0,y,0,0)
polygon(coords.x, coords.y, col = "grey")

coords.x <- c(0,70,x[200:1])
coords.y <- c(1,1,y[200:1])
polygon(coords.x, coords.y, density = 10, angle = 45)

norm.vals <- abs(rnorm(1000,0,25))
temp <- hist(norm.vals, plot = FALSE)
temp$density <- temp$density/temp$density[1]
plot(temp, freq = FALSE, add = TRUE)
```


The R package DSsim allows users to simulate distance sampling surveys and test out a range of design and analysis decisions specific to their population of interest. In order to simulate distance surveys the user must make some assuptions about the population of interest and the detection process giving rise to the observed distances. Simulations can be repeated over a range of assumptions so that the user can be confident that their chosen design will perform well despite any uncertainty.

### 1.1 Introduction to DSsim

DSsim takes information from the user on the study region, population and detection process and uses it to generate distance sampling data. DSsim can then be asked to fit detection functions to this data and produce estimates of abundance and the associated uncertainty. DSsim splits this process into three stages. Firstly, it generates an instance of a population. Secondly, it simulates the distance sampling survey using the survey design and the assumed detection function(s) provided by the user. Lastly, DSsim analyses the data from the survey. The simulation process is illustrated in Figure 1 below.

![Figure 2: Illustrates the simulation process. Blue rectangles indicate information supplied by the user. Green rectangles are objects created by DSsim in the simulation process. Orange diamonds indicate the processes carried out by DSsim.](images/SimulationDiagram.png)

### 1.2 Which Truncation Distance?

[@Buckland:2001vm] suggests truncating the data where the probability of detection is around 0.15 as a general rule of thumb. However, where to truncate data often comes up as a discussion of concern for our workshop attendants. For a start distance sampling data is often very costly to obtain and discarding some of the data points can feel counter intuitive. However, there is also concern that without truncating the data the occasional very large distance recorded these may have high influence on the parameter estimates of the detection function and possibly increase variability in estimated abundance / density. In this vignette we therefore investigate truncation distance in distance sampling analyses. 

This vignette will firstly investigate data generated assuming a simple half normal detection function where every object has the same probability of detection at a specific distance from the transect. Figure 3 shows...

```{r trunc dists1, warning=FALSE, message=FALSE, echo=FALSE, fig.width = 6, fig.cap="Figure 3: Half-normal detection function showing 3 proposed truncation distances at 1* $sigma$, 2* $sigma$ and 3* $sigma$. The truncation distance at twice sigma gives a probability of detection of 0.135 so close to the 0.15 rule of thumb."}

x <- seq(0, 80, length = 200)
scale <- 25
y <- exp(-x^2/(2*scale^2))

plot(x,y, type = "l", xlab = "Distance", ylab = "Probability of Detection", main = "Half-Normal Detection Function (sigma = 25)", lwd = 3)

# Add lines for truncation distances
x.lines <- c(25,50,75)
y.lines <- exp(-x.lines^2/(2*scale^2))

for(i in seq(along = x.lines)){
  lines(c(x.lines[i],x.lines[i]), c(0,y.lines[i]), col = 2, lwd = 3)
}


```

However, in reality individual objects or individual clusters of objects will likley have varying probability of being detected based on certain characteristics. Perhaps the behaviour of males will make them easier to detect. It is also easy to see that large clusters of individuls will be easier to spot at large distances than small clusters. Therefore secondly, we will investigate the effects of truncation distance when including individual level covariates in the simulation. Figure 4 shows how covariates may affect detectability. The most reliable way to estimate covariate effect is based on previous surveys. (Perhaps also run simulations showing not to truncate to retrieve covariate parameter estimates?)

```{r trunc dists2, warning=FALSE, message=FALSE, echo=FALSE, fig.width = 7.2, fig.cap="Figure 4: Half-normal detection function which varies based on cluster size and animal sex."}

library(DSsim)

covariate.list <- list()
covariate.list$size <- list(list("poisson", list(lambda = 35)))
covariate.list$sex <- list(data.frame(level = c("male", "female"), 
                                      prob = c(0.5,0.5)))
# Create covariate description
pop.desc <- make.population.description(covariates = covariate.list)

# define covariate parameters
cov.params <- list(size = c(0.015), 
                   sex = data.frame(level = c("male", "female"),
                                    param = c(0.9, -0.1)))
detect <- make.detectability(scale.param = 10, cov.param = cov.params, truncation = 60)

plot(detect, pop.desc)



```

### 1.3 Model Uncertainty and Pooling Robustness

When we simulate data we have to provide the detection function in order to generate detections and we therefore know the underlying true detection function. When collecting data in the real world we will not have this information and so we will rely on some form of model selection. One method of model selection is to compare information criterion, DSsim allows the user to select either AIC, AICc or BIC as the model selection criteria. For these simulations we will use AIC and allow DSsim to select between a half-normal and a hazard rate model. 

In addition, if the probability of detection is affected by covariates then we may not only have a single underlying detection function but a combination of detction functions giving rise to our observed data. In this situation we can either model detectability as a function of these covariates or rely on a concept called pooling robustness. Pooling robustness refers to the fact that distance sampling techniques are robust to the pooling of multiple detection functions. This means that we do not necessarily need to include all the covariates which affect detectability in the detection function. Here we will test the concept of pooling robustness and check to see if it is affected by truncation distance. 

## 2. Methods

This vignette will guide you through the steps to create and run a series of simulations to investigate the effects of varying truncation distance on both data generated from a simple half-normal model and from a model where detectability is affected by a covariate.

## 2.1 Setup

Here we load the DSsim library and set the random seed so that these results will be reproducible.

```{r setup, warning=FALSE, message=FALSE}
library(DSsim)
set.seed(4321)
```

## 2.2 Simulation Components

As detailed in section 1.1 a simulation comprises of a number of components. DSsim is designed so that each of these components is defined individually before they are grouped together into a simulation. This helps keep the process clear and also allows reuse of simulation components between different simulations. Each of the functions to create a simulation component or simulation takes the form _make.<component>_.

### 2.2.1 Region

These simulations will use a rectangular study region of 5 km by 20 km. Survey regions can either be defined in km or m but all units must be the same throughout the different components of the simulation. Here we will define the coordinates in m. As this is a simple study region with few verticies we can simply imput the coordinates. The structure of the coordinates is a list of data.frames for each strata. In this example we only have one polygon (so one data.frame) and one strata. 

```{r region, warning=FALSE, message=FALSE, fig.width=4, fig.cap="Figure 5: The study region."}
# Create a polgon
poly1 <- data.frame(x = c(0,0,20000,20000,0), y = c(0,5000,5000,0,0))

# Create an empty list
coords <- list()
# Store the polygon inside a list in the first element of the coords list referring to strata 1.
coords[[1]] <- list(poly1)

# Create the survey region
region <- make.region(region.name = "study area", 
                      units = "m",
                      coords = coords)
# The plot function allows plotting in km or m.
plot(region, plot.units = "km")

```

### 2.2.2 Population

We will now define our population within our study region. Firstly, we must describe the distribution of the population by defining a density grid. For these simulations we will assume a uniform distribution of animals throughout the study region. DSsim will generate this grid for us if we provide the x and y spacing and a constant density value for the grid. In this example the value of the constant is not important as we will generate animals based on a fixed population size rather than the density grid.

```{r density, warning=FALSE, message=FALSE, fig.width=4, fig.cap="Figure 6: The density surface."}

# Create the density surface
density <- make.density(region.obj = region, 
                        x.space = 50, 
                        y.space = 200, 
                        constant = 1)

# The plot function allows plotting in km or m.
plot(density, style = "blocks", plot.units = "km")
plot(region, add = TRUE)

```

We can now define other aspects of the population. For the simple case (with no covariates) we only need to define a fixed population size and provide the region and density grid we created above.

```{r popdesc1, warning=FALSE, message=FALSE}

# Create the population description, with a population size N = 200
pop.desc <- make.population.description(region.obj = region, 
                                            density.obj = density, 
                                            N = 200)

```


For our simulations involving covariates we need to define how individuals will be allocated these covariate values. DSsim allows the user to either define their own discrete distribution or alternatively provide a distribution with associated parameters. For these simulation we will use sex as a covariate and assume that 50% of the population are female and 50% are male.

*Blurb about why we chose this population size*


```{r popdesc2, warning=FALSE, message=FALSE}

# Create the covariate list
covariate.list <- list()
# The population will be 50% males and 50% females
covariate.list$sex <- list(data.frame(level = c("female", "male"), prob = c(0.5,0.5)))

# Create the population description, with a population size N = 200
pop.desc.cov <- make.population.description(region.obj = region, 
                                            density.obj = density, 
                                            covariates = covariate.list, 
                                            N = 200)

```


### 2.2.3 Detectability

Detectability refers to the detection function or functions we feed into the simulation to generate the observations. In the simple case we can set all animals to have the same probability of detection given their distance from the transect. Here we define a half-normal detection function with scale parameter 200 and truncation 600. The truncation distance defined here means that no detections will occur beyond this value. We can then plot this function to check we have defined it correctly. As we defined our survey region in m the scale parameter and truncation distance will also be assumed to be in metres.

The scale parameter of 200 was selected as on average it gives around 100 detections out to a truncation distance of 600m where detectability is very low.

```{r detect1, warning=FALSE, message=FALSE, fig.width=4, fig.cap="Figure 7: The detection functions for males and females."}

# Make a simple half normal detection function with a scale parameter of 10
detect.hn <- make.detectability(key.function = "hn",
                                 scale.param = 200, 
                                 truncation = 600)

# We can now visualise these detection functions
plot(detect.hn, pop.desc)
```

When we have covariates in the population we may choose to vary the scale parameter of the detection function based on the covariate values. DSsim assumes that the scale parameter is a function of the covariates as follows:

$$ \sigma = exp(\beta_0+\sum_{j=1}^{q}\beta_{j}z_{ij}) $$

where $\beta_0$ is the log of the scale parameter supplied to make.detectability, $beta_j$ are the covariate parameters on the log scale and $z_{ij}$ is the ith value of the jth covariate. This formula was taken from @Buckland:2004ts.

The covariate values were selected so that males had a higher probability of detection than females. These particular values again give a sample size of about 100 observations to which the detection function(s) can be fitted.

```{r detect2, warning=FALSE, message=FALSE, fig.width=4, fig.cap="Figure 8: The detection functions for males and females."}

# Create the covariate parameter list
cov.params <- list()
# Note the covariate parameters are supplied on the log scale
cov.params$sex = data.frame(level = c("female", "male"), 
                            param = c(0, 1))

# We want a scale parameter of around 10 for the females and 25 for the males
# The scale parameter is supplied on the natural scale so...
exp(log(100) + 1)
detect.cov <- make.detectability(scale.param = 110,  cov.param = cov.params, truncation = 600)

# We can now visualise these detection functions
plot(detect.cov, pop.desc.cov)
```

### 2.2.4 Design

DSsim-1.1.0 implements two basic designs, systematic parallel lines and systematic points, to generate transects. Other more complex designs can be used with the aid of the Distance for Windows software [@Thomas:2010cf]. This software allows more complex designs to be defined and can generate transects and store them in the form of shapefiles which DSsim can then read in. 

For the purposes of this example we will use the parallel systematic line transect design built into DSsim. As the recommended minimum number of transects is between 10 and 20 [@Buckland:2001vm] we have set the spacing between the lines to be 1000 m.

```{r design, warning=FALSE, message=FALSE}

# Define the design
design <- make.design(transect.type = "line",
                      design.details = c("parallel", "systematic"),
                      region.obj = region,
                      spacing = 1000)

```

```{r transects, warning=FALSE, message=FALSE, echo = FALSE, fig.width=4, fig.cap="Figure 9: Example survey transects."}

transects <- generate.transects(design, region = region)
plot(region, plot.units = "km")
plot(transects, col = 4, lwd = 2)
```

### 2.2.5 Analysis

The final stage of the simulation is to analyse the distance sampling data which has been generated. As discussed above when collecting data in the field we would not know the true underlying detection function, we will therefore incorporate some model uncertainty. We can ask the simulation to fit two models, a half-normal and a hazard rate, to the data and select the best model based on the minimum AIC as follows:

```{r analyses1}
ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1),
                                                      ~cds(key = "hr", formula = ~1)), 
                                       method = "ds",
                                       criteria = "AIC",
                                       truncation = 500)
```

In this code we have set the truncation distance to 500 but later we will vary this value to investigate the effects of truncation distance on our simulation results. Note that while the truncation distance can be set to any value, it should not exceed the truncation value defined in the detectability.

In addition, in the field it may be possible to identify the covariates that affect detectability so we may wish to fit a detection function that accounts for this. In this example the following model would be appropriate:

```{r analyses2}
ddf.analyses.cov <- make.ddf.analysis.list(dsmodel = list(~mcds(key = "hn", formula = ~sex)), 
                                           method = "ds",
                                           truncation = 500)
```

## 2.3 Simulations

The simulation is created by grouping all these components together. It is then a good idea to check that everything is as you indended. The function \code{check.sim.setup} provides a number of plots to help you do this. 

```{r check.sim, fig.height=5.5, fig.width=7.2, fig.cap="Figure 10: Example survey. Top left - the density suface with an example population. Top right - an example set of transects. Bottom left - the detections from the transects. Bottom right - A histogram of the distances from these observations to the transect it was detected."}
sim <- make.simulation(reps = 999, 
                       region.obj = region,
                       design.obj = design,
                       population.description.obj = pop.desc,
                       detectability.obj = detect.hn,
                       ddf.analyses.list = ddf.analyses)

check.sim.setup(sim)
```

For the simulation with covatiates we can re-use the region, design and analysis components and then add in the new population description and detecability.

```{r check.sim2, fig.height=5.5, fig.width=7.2, fig.cap="Figure 11: Example survey."}
sim.cov <- make.simulation(reps = 999, 
                       region.obj = region,
                       design.obj = design,
                       population.description.obj = pop.desc.cov,
                       detectability.obj = detect.cov,
                       ddf.analyses.list = ddf.analyses)
```

## 2.4 Running Multiple Simulations

```{r check.sim3, eval = FALSE}

truncation <- c(200, 400, 600)
results.list <- list()
summary.list <- list()

for(tdist in seq(along= truncation)){
  # Update analysis truncation distance
  new.ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1),
                                                            ~cds(key = "hr", formula = ~1)), 
                                             method = "ds",
                                             criteria = "AIC",
                                             truncation = truncation[tdist])
  # Update simulation
  sim@ddf.analyses <- new.ddf.analyses
  sim@reps <- 10
  # Run Simulation
  results.list[[tdist]] <- run(sim)
  # Store simulation summaries
  summary.list[[tdist]] <- summary(results.list[[tdist]], description.summary = FALSE)
}


```

```{r check.sim4, eval = FALSE}

truncation <- c(200, 400, 600)
cov.results.list <- list()
cov.summary.list <- list()

for(tdist in seq(along= truncation)){
  cat("Iteration: ", tdist, fill = TRUE)
  # Update analysis truncation distance
  new.ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1),
                                                      ~cds(key = "hr", formula = ~1)), 
                                       method = "ds",
                                       criteria = "AIC",
                                       truncation = truncation[tdist])
  # Update simulation
  sim.cov@ddf.analyses <- new.ddf.analyses
  # Run Simulation
  cov.results.list[[tdist]] <- run(sim.cov)
  # Store simulation summaries
  cov.summary.list[[tdist]] <- summary(cov.results.list[[tdist]], description.summary = FALSE)
}


```

## 3. Results

### 3.1 Extracting Result Statistics

If you have only run a single simulation then a summary of the description and results can be viewed as follows:


However, as this investigation involved running many simulations we provide a function to automate the extraction of results, assuming a number of simulations are stored in a list. It is not necessary to understand how these functions work, details are provided here for interested readers. If prefered the reader could just run the code and skip to the next section.


This function is then then applied over the list of simulations to extract the desired results using _lapply_.


## 3.2 Simulation Results


##5. The Conclusions

Changing the truncation distance did not lead to big differences in the % Bias however there was a clear trend in precision.  Since each simulation was successfully run the same number of times we could use the RMSE as a meaningful comparison to combine the two and found that truncating less data was better by this metric.  However, differences were small even at this small sample size and so truncation distance should not be a big concern at the analysis stage.  It should also be noted that the observers for the survey should not be given a truncation distance because if they see something just beyond this distance they may be tempted to record it at the truncation distance which will lead to heaping at this distance. 

##6. References



