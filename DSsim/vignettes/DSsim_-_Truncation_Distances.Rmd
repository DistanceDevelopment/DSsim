---
title: "Using DSsim to investigate Truncation Distances"
author: "Kieran Richards, Laura Marshall"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{DSsim - Truncation Distances}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## 1. Introduction

Distance Sampling is a process in which a study area is surveyed so that the size of the population within it can be estimated. It can be thought of as an extension to plot sampling. However, while plot sampling assumes that all animals within the plots are detected, distance sampling relaxes this assumption. By fitting a detection function to the recorded distances from the objects to a transect we can estimate how many objects were missed. In order to simulate distance surveys the user must make some assuptions about the population of interest and the detection process giving rise to the observed distances. Simulations can be repeated over a range of assumptions so that the user can be confident that their chosen design will perform well despite any uncertainty.

### 1.1 Introduction to DSsim

DSsim takes information from the user on the study region, population and detection process and uses it to generate distance sampling data. DSsim can then be asked to fit detections functions to this data and produce estimates of abundance and the associated uncertainty.  DSsim splits this process into three stages. Firstly, it generates an instance of a population. Secondly, it simulates the distance sampling survey using the survey design and the assumed detection function(s) provided by the user. Lastly, DSsim analyses the data from the survey. The simulation process is illustrated in Figure 1 below.

![Figure 1: Illustrates the simulation process. Blue rectangles indicate information supplied by the user. Green rectangles are objects created by DSsim in the simulation process. Orange diamonds indicate the processes carried out by DSsim.](images/SimulationDiagram.png)

### 1.2 Which Truncation Distance?

When fitting a detection function the data is usually truncated at some distance from the transect. This is because the detections closer to the transect are considered to be of greater importance in the detection function estimation process. In addition, if there is the occasional very large distance recorded these may have high influence on the parameter estimates of the detection function and possibly increase their estimated variability. [@Buckland:2001vm] suggests truncating the data where the probability of detection is 0.15 as a general rule of thumb. Here we test the effects of different truncation distances using DSsim.

This vignette demonstrates how DSsim can be used to explore how truncation distances affects the accuracy and precision of the estimated of a population size. Simulations will be run with truncation distances at different multiples of $\sigma$ as shown in Figure 2. We have repeated these simulation for both a half-normal detection function and a hazard-rate detection function. The suggested truncation distance based on [@Buckland:2001vm]'s 0.15 rule is approximately 2$\sigma$ for the half-normal and approximately 1.5$\sigma$ for a hazard rate detection function with shape parameter 4. 

![Figure 2: Left hand plot shows a half-normal detection function with truncation distances indicated by vertical lines at 1.25$\sigma$, 1.5$\sigma$, 1.75$\sigma$, 2$\sigma$, 2.5$\sigma$ and 3$\sigma$. Right hand plot shows a hazard-rate detection function with  truncation distances indicated by vertical lines at 1.25$\sigma$, 1.5$\sigma$, 1.75$\sigma$, 2$\sigma$, 2.5$\sigma$ and 3$\sigma$.](images/Rplots.png)

### 1.3 Model Uncertainty

We have various options when running simulation on what to do about model selection. We can only allow DSsim to fit the model which we know to be the true model or we can allow DSsim to select the model which it considers the best fit based on some criteria. In reality we will never know the true detection function so it would seem sensible to allow DSsim to select the best fitting model. In these simulations we compare the results of both fitting what we know to be the true detection function and allowing DSsim to choose *NEED TO EXPAND*

## 2. Methods

This vignette will guide you through the steps to create and run a series of simulations to investigate the effects of varying truncation distance.

### 2.1 Setup

The package needs to be loaded and also the seed has been set so that the results in this vignette can be easily reproduced.  The package _shapefiles_ will also be required. 
```{r setup, warning=FALSE, message=FALSE}
library(DSsim)
library(shapefiles)
set.seed(4321)
```

## 2.2 Simulation Components

We are now going to create the components relating to the blue rectangles in Figure 1. All constructor functions take the form _make.object_.

### 2.2.1 Region

Firstly we define the study region, a simple 20,000m by 5,000m rectangular region. To do this we will load a shapefile containing a polygon of these dimenstions to me passed to the _make.region_ function. To estimate the abundance in a region DSsim needs the area of the region. This can either be supplied by the user or if not supplied DSsim will calculate it automatically using the _areapl_ function from the _splancs_ package [@splancs-pkg]. The following code creates the region and diplays it in Figure 3:

```{r region, fig.cap="Figure 3: A plot of the study region.", fig.align="center", fig.width = 7, fig.height = 3}
region.shapefile <- read.shapefile("Study_ar") #DSsim assumes there is a shapefile called this in the R working directory
region <- make.region(region.name = "Survey Region", 
                      units = "m", 
                      shapefile = region.shapefile)
plot(region)
```

### 2.2.2 Population

Next we must describe the population of interest. This first involves creating a density map showing how the population is distributed within the survey region. For this study we will use a constant density over the whole surface. The value of this constant is not important in this simulation as we will later define a fixed population size so the density surface is only used to provide relative density values across the study area. The _x.space_ and _y.space_ arguments describe the spacing of the density surface grid points, as we have a constant density surface we can afford to make the grid fairly course. However, if the density surface varies then it may be wise to decrease the spacing between grid points to allow finer detail to be represented.  This code produces the density object and plots it over the region, Figure 4.

```{r density, fig.cap="Figure 4 - A plot of the study region with a heat map showing the population density overlayed", fig.align="center", fig.width = 7, fig.height = 3}
pop.density <- make.density(region = region, 
                            x.space = 1000, 
                            y.space = 1000, 
                            constant = 1) 
plot(pop.density, plot.units = "m", style = "blocks")
plot(region, add = TRUE)
```

We can now combine this density object with other population parameters to create the full population description. We will use a fixed population size of N=250. We have chosen 250 because combined with the detection function we have selected this results in around 60 observations, the minimum number recommended for fitting a detection function, [@Buckland:2001vm].  

```{r population}
pop.description <- make.population.description(region.obj = region, 
                                               density.obj = pop.density, 
                                               N = 250, 
                                               fixed.N = TRUE)
```

### 2.2.3 Detectability

Detectability refers to how easy we think it will be to detect an object, this is just the detection function we feed in to the simulation in order to generate the detections. This detection function is used to calculate the probability each object in the population could be detected from each transect based on its distance to that transect. These probabilites are then turned into detections (or not) based on a Bernoulli distribution. These simulations generate data based on both a half-normal and a hazard-rate detection function. We can also specify a truncation distance which is the largest distance at which an animal may be detected, this is not necessarily the same as the truncation distance applied in the analysis stage.

```{r detection}
detect.hn <- make.detectability(key.function = "hn", 
                             scale.param = 100, 
                             truncation = 500)

detect.hr <- make.detectability(key.function = "hr", 
                             scale.param = 120, 
                             shape.param = 3,
                             truncation = 500)
```

### 2.2.4 Design

Currently DSsim requires that the surveys (teansects) have been pregenerated from a design and are stored in their own folder as shapefiles. We recommend this is done using the automated survey design engine in the Distance for Windows software [@Thomas:2010cf]. The arguments passed to the _make.design_ function therefore mainly only store a record of the parameters used to create the pregenerated surveys they will not affect the simulation. We generated surveys based on a systematic parallel line transect design with a spacing of 1000m between transects and orientated the lines vertically so that they were running across the narrower dimension of the study region giving 20 transects per survey. The recommended minimum number of transects for line transect studies is between 10 and 20 [@Buckland:2001vm].

```{r design}
parallel.design <- make.design(transect.type = "Line", 
                               design.details = c("Parallel","Systematic"), 
                               spacing = 1000,
                               design.axis = 90,
                               region.obj = region, 
                               path = "shapefiles")
```

### 2.2.5 Analysis

Finally we can define how to analyse the resulting distance samplig data. Below we restrict DSsim to only fitting a half-normal model with a truncation distance of 125m (1.25$\sigma$).

```{r analyses}
ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1)), 
                                       method = "ds", 
                                       truncation = 125)
```

However, as discussed earlier we may wish to allow DSsim to perform model selection between a number of candidate models as we will not know in a real worl example what the true detection fucntion is. The code below can be used to allow DSsim to select between a half-normal and a hazard-rate model based on the minimum AIC value.  

```{r analyses2}
ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), 
                                                          ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "AIC", 
                                           truncation = 125)
```

## 2.3 Simulations

### 2.3.1 Running a single simulation

Once all the individual parts of the simulation have been created they are grouped together inside a simulation object. The reason they are all grouped together is so that a summary can be provided of all the components and it is always clear which settings have been used to run the simulation. We will run this simulation 999 times using a different set of transects on each iteration.

```{r make.sim}
simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect.hn, 
                               ddf.analyses.list = ddf.analyses)
```

As simulations can take a long time to run it is often worth checking that the setup is right first. We can view an example population, an example transect set, an example survey and a histogram of example detection distances. These are shown in Figure 5.

```{r gen.pop, fig.cap="Figure 5: Top left - the locations of the population objects. Top right - one set of transects. Bottom left - An example realisation of a survey with the red points indicating the undetected objects and the cyan points indicating the detected objects. Bottom right - Histogram of perpendicular distances from the transects to each of the detected objects shown in bottom left panel.", fig.align="center", fig.width = 7, fig.height = 5}
par(mfrow = c(2,2))
# Example population
pop <- generate.population(simtrunc125)
plot(region)
plot(pop)
# Example transects
transects <- generate.transects(simtrunc125)
plot(region)
plot(transects, col = 4, lwd = 2)
# Example detections
eg.survey <- create.survey.results(simtrunc125)
plot(eg.survey)
# Example distances
dist.data <- get.distance.data(eg.survey)
hist(dist.data$distance, xlab = "Distance (m)", main = "Distance Data")
```

If the setup has been done right the simulation can now be run but first we will reset the seed so that subsequent simulations use the same population:
```{r first.sim, warning=FALSE, message=FALSE, eval=FALSE}
set.seed(4321)
simtrunc125 <- run(simtrunc125)
```

### 2.3.1 Running multiple simulations

For our simulation we wanted to run similar simulations only changing the analysis truncation distance between runs. Here we give an example with no model uncertainty.

```{r sims, eval=FALSE}
# Truncation distances as a function of sigma
sigma = 100
Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
# List to store simulations with results on completion
sims <- vector("list", length(Trun.dists))
# Loop over all the truncation distances
for(i in 1:6){
  set.seed(4321)
  # Update the truncation distance
  ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1)), 
                                         method = "ds", 
                                         truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect.hn, 
                         ddf.analyses.list = ddf.analyses)
  sims[[i]]  <- run(sim)
}
```


A summary of the other simulations completed as part of this study are detailed in Table 1 below. We generated data both assuming a half-normal and hazard-rate detection function and then allowed model selection based on either AIC or BIC. It was important to test the selection criteria assuming a hazard-rate detection function as well as a half-normal as the two have different numbers of parameters. As the half-normal only has one parameter we may find that the BIC performs slightly better, however this harsher penalty may cause less precise results in the instance that the true detection function is a hazard rate.

```{r message=FALSE}
library(knitr)
```


```{r simulation.desc="asis", fig.cap = "Table 1 - Description of simulations", echo=FALSE}
simulation.desc <- data.frame(ID = 1:5,
                              detect = c(rep("detect.hn",3),rep("detect.hr",2)),
                              trunc = c(rep("125, 150, 175, 200, 250, 300m",3),
                                        rep("150, 180, 210, 240, 300, 360m",2)),
                              models = c("hn", rep("hn v hr",4)),
                              criteria = c(NA, rep(c("AIC","BIC"),2)))
table<-kable(simulation.desc, 
             col.names = c("ID","Detectability", "Truncation", "Candidate Model(s)", "Criteria"),
             align = c('c', 'c', 'c', 'c', 'c'))

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Descriptions", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```


```{r model_selection_sims_not_run, echo=FALSE, eval=FALSE}
ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "AIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.aic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "AIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.aic)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsAIC.rda")

ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "BIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.bic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "BIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.bic)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsBIC.rda")

set.seed(4321)
# region.shapefile <- read.shapefile("Study_ar") #DSsim assumes there is a shapefile called this in the R working directory
# region <- make.region(region.name = "Survey Region", 
#                       units = "m", 
#                       shapefile = region.shapefile)
# pop.density <- make.density(region = region, 
#                             x.space = 1000, 
#                             y.space = 1000, 
#                             constant = 1)
# pop.description <- make.population.description(region.obj = region, 
#                                                density.obj = pop.density, 
#                                                N = 250, 
#                                                fixed.N = TRUE)
# parallel.design <- make.design(transect.type = "Line", 
#                                design.details = c("Parallel","Systematic"), 
#                                region.obj = region, 
#                                path = "shapefiles")

sigma = 120
shape = 3
detect <- make.detectability(key.function = "hr", 
                             scale.param = sigma, 
                             shape.param = shape,
                             truncation = 500)

ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "AIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.aic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "AIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.aic)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsAIChrkey.rda")

ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "BIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.bic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims.hr.bic <- vector("list", length(Trun.dists))
sims.hr.bic[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "BIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.bic)
  sim  <- run(sim)
  sims.hr.bic[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsBIChrkey.rda")
```
Since these simulations take a long time to run we have run them in advance and saved the results as data in the DSsim package.  Each of these objects is a list of simulations with varying truncation distance relating to Table 1.  We can use the following code to load these results:
```{r}
# Simulation ID=1
data("truncationResults")
# Simulation ID=2
data("truncationResultsAIC")
# Simulation ID=3
data("truncationResultsBIC")
# Simulation ID=4
data("truncationResultsAIChrkey")
# Simulation ID=5
data("truncationResultsBIChrkey")
```

## 3. Results

### 3.1 Extracting Result Statistics

If you have only run a single simulation then a summary of the description and results can be viewed as follows:

```{r summary, eval=FALSE}
#Not run
summary(simtrunc125)
```

However, as this investigation involved running many simulations we provide a function to automate the extraction of results, assuming a number of simulations are stored in a list. It is not necessary to understand how these functions work, details are provided here for interested readers. If prefered the reader could just run the code and skip to the next section.

```{r}
extract.info <- function(simulation, info.name){
  switch(info.name,
         N = simulation@population.description@N,
         reps = simulation@reps,
         truncation.distance = simulation@ddf.analyses[[1]]@truncation,
         n = simulation@results$individuals$summary[1,4,1000],
         estimated.abundance = simulation@results$individuals$N[1,1,1000],
         mean.se = simulation@results$individuals$N[1,2,1000],
         percentage.bias = 100*((simulation@results$individuals$N[1,1,1000] 
                                 - simulation@population.description@N)
                                /simulation@population.description@N),
         RMSE = sqrt(sum((simulation@results$individuals$N[1,1,1:simulation@reps] 
                          - simulation@population.description@N)**2, na.rm = TRUE)/simulation@reps))
}
```

This function is then then applied over the list of simulations to extract the desired results using _lapply_.

```{r}
Trunc.Dist <- lapply(sims, extract.info, info.name = "truncation.distance")
n          <- lapply(sims, extract.info, info.name = "n")
Est.Abund  <- lapply(sims, extract.info, info.name = "estimated.abundance")
mean.se    <- lapply(sims, extract.info, info.name = "mean.se")
Perc.Bias  <- lapply(sims, extract.info, info.name = "percentage.bias")
RMSE.orig  <- lapply(sims, extract.info, info.name = "RMSE")
```


## 3.2 Simulation Results

Once the results have been extracted the function _kable_ from the package _knitr_ will be used to table the results:

Then the results must be combined into a data frame to be tabled:
```{r}
simulation.data = cbind(Trunc.Dist = Trunc.Dist, 
                        n = n, 
                        Est.Abund = Est.Abund, 
                        mean.se = mean.se, 
                        Perc.Bias = Perc.Bias, 
                        RMSE = RMSE.orig)
```


Finally the results can be tabled.  The align argument has been used  to centre the results in each column and the digits argument has been used to specify the number of decimal places in each column. 
```{r results="asis", fig.cap = "Table 1 - The results from the simulations"}
table<-kable(simulation.data, 
             digits = 2, 
             col.names = c("$Trunc Dist$", "$n$", "$Mean \\hat{N}$", "$SE$", "$\\% Bias$", "$RMSE$"),
             align = c('c', 'c', 'c', 'c', 'c', 'c', 'c') )

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Results", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```

```{r echo=FALSE}
#NEED TO ADD MODEL SELECTION CRITERIA
Trunc.Dist.aic <- lapply(sims.aic, extract.info, info.name = "truncation.distance")
n.aic          <- lapply(sims.aic, extract.info, info.name = "n")
Est.Abund.aic  <- lapply(sims.aic, extract.info, info.name = "estimated.abundance")
mean.se.aic    <- lapply(sims.aic, extract.info, info.name = "mean.se")
Perc.Bias.aic  <- lapply(sims.aic, extract.info, info.name = "percentage.bias")
RMSE.aic       <- lapply(sims.aic, extract.info, info.name = "RMSE")

Trunc.Dist.bic <- lapply(sims.bic, extract.info, info.name = "truncation.distance")
n.bic          <- lapply(sims.bic, extract.info, info.name = "n")
Est.Abund.bic  <- lapply(sims.bic, extract.info, info.name = "estimated.abundance")
mean.se.bic    <- lapply(sims.bic, extract.info, info.name = "mean.se")
Perc.Bias.bic  <- lapply(sims.bic, extract.info, info.name = "percentage.bias")
RMSE.bic       <- lapply(sims.bic, extract.info, info.name = "RMSE")

Trunc.Dist <- c(Trunc.Dist.aic, Trunc.Dist.bic)
n          <- c(n.aic, n.bic)
Est.Abund  <- c(Est.Abund.aic, Est.Abund.bic)
mean.se    <- c(mean.se.aic, mean.se.bic)
Perc.Bias  <- c(Perc.Bias.aic, Perc.Bias.bic)
RMSE       <- c(RMSE.aic, RMSE.bic)
```

```{r echo = FALSE}
simulation.modelselect.data = cbind(Trunc.Dist = Trunc.Dist, 
                                    n=n,
                                    Est.Abund = Est.Abund,
                                    mean.se = mean.se, 
                                    Perc.Bias = Perc.Bias, 
                                    RMSE=RMSE)
```

```{r results="asis", fig.cap = "Table 2 - The results from the model selection simulations", echo = FALSE}
table<-kable(simulation.data, 
             digits = 2, 
             col.names = c("$Trunc Dist$", "$n$", "$Mean \\hat{N}$", "$SE$", "$\\% Bias$", "$RMSE$"),
             align = c('c', 'c', 'c', 'c', 'c', 'c', 'c') )

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Results", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```

```{r echo=FALSE}
#NEEDS MODEL SELECTION CRITERIA
Trunc.Dist.hr.aic <- lapply(sims.hr.aic, extract.info, info.name = "truncation.distance")
n.hr.aic          <- lapply(sims.hr.aic, extract.info, info.name = "n")
Est.Abund.hr.aic  <- lapply(sims.hr.aic, extract.info, info.name = "estimated.abundance")
mean.se.hr.aic    <- lapply(sims.hr.aic, extract.info, info.name = "mean.se")
Perc.Bias.hr.aic  <- lapply(sims.hr.aic, extract.info, info.name = "percentage.bias")
RMSE.hr.aic       <- lapply(sims.hr.aic, extract.info, info.name = "RMSE")

Trunc.Dist.hr.bic <- lapply(sims.hr.bic, extract.info, info.name = "truncation.distance")
n.hr.bic          <- lapply(sims.hr.bic, extract.info, info.name = "n")
Est.Abund.hr.bic  <- lapply(sims.hr.bic, extract.info, info.name = "estimated.abundance")
mean.se.hr.bic    <- lapply(sims.hr.bic, extract.info, info.name = "mean.se")
Perc.Bias.hr.bic  <- lapply(sims.hr.bic, extract.info, info.name = "percentage.bias")
RMSE.hr.bic       <- lapply(sims.hr.bic, extract.info, info.name = "RMSE")

Trunc.Dist <- c(Trunc.Dist.hr.aic, Trunc.Dist.hr.bic)
n          <- c(n.hr.aic, n.hr.bic)
Est.Abund  <- c(Est.Abund.hr.aic, Est.Abund.hr.bic)
mean.se    <- c(mean.se.hr.aic, mean.se.hr.bic)
Perc.Bias  <- c(Perc.Bias.hr.aic, Perc.Bias.hr.bic)
RMSE       <- c(RMSE.hr.aic, RMSE.hr.bic)
```

```{r echo = FALSE}
simulation.modelselect.hr.data = cbind(Trunc.Dist = Trunc.Dist, 
                                       n=n, 
                                       Est.Abund = Est.Abund, 
                                       mean.se = mean.se, 
                                       Perc.Bias = Perc.Bias, 
                                       RMSE=RMSE)
```

```{r results="asis", fig.cap = "Table 3 - The results from the model selection simulations when the true detection function has a hazard rate key", echo = FALSE}
table<-kable(simulation.modelselect.hr.data, 
             digits = 2, 
             col.names = c("$Trunc Dist$", "$n$", "$Mean \\hat{N}$", "$SE$", "$\\% Bias$", "$RMSE$"),
             align = c('c', 'c', 'c', 'c', 'c', 'c', 'c') )

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Results", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```

For distance sampling surveys it is usually recommended to have a minimum of 60-80 detections[@Buckland:2001vm] however even at this small number of observations $\% Bias$ is small.  Increasing the truncation distance does seem to have increased this bias slightly however there is clearly a trend in RMSE which shows that the increase in precision, which can be seen in the standard error, greatly outweighs this effect:
```{r fig.cap = "Figure 9 - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5}
plot(Trunc.Dist[1:6], RMSE.orig)
```

```{r fig.cap = "Figure 9b - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.aic)
```

```{r fig.cap = "Figure 9c - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.bic)
```

```{r fig.cap = "Figure 9d - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.hr.aic)
```

```{r fig.cap = "Figure 9e - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.hr.bic)
```

```{r fig.cap = "Figure 10 - The red line indicates the true size of the population while the blue dots are the means of the estimates.  There is no clear trend in the accuracy of the estimate however it is easy to see that the precision improves considerably when less data is truncated", fig.align="center", fig.width = 5, fig.height = 5}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims[[1]]@results$individuals$N[1,1,1:999], sims[[2]]@results$individuals$N[1,1,1:999], sims[[3]]@results$individuals$N[1,1,1:999], sims[[4]]@results$individuals$N[1,1,1:999], sims[[5]]@results$individuals$N[1,1,1:999], sims[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 11", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.aic[[1]]@results$individuals$N[1,1,1:999], sims.aic[[2]]@results$individuals$N[1,1,1:999], sims.aic[[3]]@results$individuals$N[1,1,1:999], sims.aic[[4]]@results$individuals$N[1,1,1:999], sims.aic[[5]]@results$individuals$N[1,1,1:999], sims.aic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 12", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.bic[[1]]@results$individuals$N[1,1,1:999], sims.bic[[2]]@results$individuals$N[1,1,1:999], sims.bic[[3]]@results$individuals$N[1,1,1:999], sims.bic[[4]]@results$individuals$N[1,1,1:999], sims.bic[[5]]@results$individuals$N[1,1,1:999], sims.bic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 13", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.hr.aic[[1]]@results$individuals$N[1,1,1:999], sims.hr.aic[[2]]@results$individuals$N[1,1,1:999], sims.hr.aic[[3]]@results$individuals$N[1,1,1:999], sims.hr.aic[[4]]@results$individuals$N[1,1,1:999], sims.hr.aic[[5]]@results$individuals$N[1,1,1:999], sims.hr.aic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 14", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.hr.bic[[1]]@results$individuals$N[1,1,1:999], sims.hr.bic[[2]]@results$individuals$N[1,1,1:999], sims.hr.bic[[3]]@results$individuals$N[1,1,1:999], sims.hr.bic[[4]]@results$individuals$N[1,1,1:999], sims.hr.bic[[5]]@results$individuals$N[1,1,1:999], sims.hr.bic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```
##5. The Conclusions

Changing the truncation distance did not lead to big differences in the % Bias however there was a clear trend in precision.  Since each simulation was successfully run the same number of times we could use the RMSE as a meaningful comparison to combine the two and found that truncating less data was better by this metric.  However, differences were small even at this small sample size and so truncation distance should not be a big concern at the analysis stage.  It should also be noted that the observers for the survey should not be given a truncation distance because if they see something just beyond this distance they may be tempted to record it at the truncation distance which will lead to heaping at this distance. 

##6. References



