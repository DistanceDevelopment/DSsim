---
title: "Using DSsim to investigate Truncation Distances"
author: "Kieran Richards, Laura Marshall"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{DSsim - Truncation Distances}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## 1. Introduction

Distance Sampling is a process in which a study area is surveyed so that the size of the population within it can be estimated. It can be thought of as an extension to plot sampling. However, while plot sampling assumes that all animals within the plots are detected, distance sampling relaxes this assumption. By fitting a detection function to the recorded distances from the objects to a transect we can estimate how many objects were missed. In order to simulate distance surveys the user must make some assuptions about the population of interest and the detection process giving rise to the observed distances. Simulations can be repeated over a range of assumptions so that the user can be confident that their chosen design will perform well despite any uncertainty.

### 1.1 Introduction to DSsim

DSsim takes information from the user on the study region, population and detection process and uses it to generate distance sampling data. DSsim can then be asked to fit detections functions to this data and produce estimates of abundance and the associated uncertainty.  DSsim splits this process into three stages. Firstly, it generates an instance of a population. Secondly, it simulates the distance sampling survey using the survey design and the assumed detection function(s) provided by the user. Lastly, DSsim analyses the data from the survey. The simulation process is illustrated in Figure 1 below.

![Figure 1 - Illustrates the simulation process. Blue rectangles indicate information supplied by the user. Green rectangles are objects created by DSsim in the simulation process. Orange diamonds indicate the processes carried out by DSsim.](images/SimulationDiagram.png)

### 1.2 Which Truncation Distance?

When fitting a detection function the data is usually truncated at some distance from the transect. This is because the detections closer to the transect are considered to be of greater importance in the detection function estimation process. In addition, if there is the occasional very large distance recorded these may have high influence on the parameter estimates of the detection function and possibly increase their estimated variability. [@Buckland:2001vm] suggests truncating the data where the probability of detection is 0.15 as a general rule of thumb. Here we test the effects of different truncation distances using DSsim.

This vignette demonstrates how DSsim can be used to explore how truncation distances affects the accuracy and precision of the estimated of a population size. Simulations will be run with truncation distances at different multiples of $\sigma$ as shown in Figure 2. We have repeated these simulation for both a half-normal detection function and a hazard-rate detection function. The suggested truncation distance based on [@Buckland:2001vm]'s 0.15 rule is approximately 2$\sigma$ for the half-normal and approximately 1.5$\sigma$ for a hazard rate detection function with shape parameter 4. 

![Figure 2 - Left hand plot shows a half-normal detection function with truncation distances indicated by vertical lines at 1.25$\sigma$, 1.5$\sigma$, 1.75$\sigma$, 2$\sigma$, 2.5$\sigma$ and 3$\sigma$. Right hand plot shows a hazard-rate detection function with  truncation distances indicated by vertical lines at 1.25$\sigma$, 1.5$\sigma$, 1.75$\sigma$, 2$\sigma$, 2.5$\sigma$ and 3$\sigma$.](images/Rplots.png)

### 1.3 Model Uncertainty

We have various options when running simulation on what to do about model selection. We can only allow DSsim to fit the model which we know to be the true model or we can allow DSsim to select the model which it considers the best fit based on some criteria. In reality we will never know the true detection function so it would seem sensible to allow DSsim to select the best fitting model. In these simulations we compare the results of both fitting what we know to be the true detection function and allowing DSsim to choose *NEED TO EXPAND*

##2. Methods

This vignette will guide you through the steps to create and run a series of simulations to investigate the effects of varying truncation distance.  For the advanced reader we also include sections describing how to save the data from a simulation in order to speed up subsequent simulations using the same population and on how to include model selection in the investigation.

###2.1 Setup

The package needs to be loaded and also the seed has been set so that the results in this vignette can be easily reproduced.  The package _shapefiles_ will also be required. 
```{r setup, warning=FALSE, message=FALSE}
library(DSsim)
library(shapefiles)
set.seed(4321)
```

##2.2 Making the Simulation Components

###2.2.1 Region
The first part of the simulation is the region.  For the investigation a simple 20,000m by 5,000m rectangular region will be used.  This requires a shapefile which describes the region.  To estimate the abundance in the region DSsim needs the area of the region.  DSsim calculates this automatically using _areapl_ from the _splancs_ package [@splancs-pkg].  If this is not suitable then DSsim can be provided with an area that has been calculated elsewhere using the area argument of _make.region_.  The following code creates the region and plots it in Figure 3:
```{r region, fig.cap="Figure 3 - A plot of the study region", fig.align="center", fig.width = 7, fig.height = 3}
region.shapefile <- read.shapefile("Study_ar") #DSsim assumes there is a shapefile called this in the R working directory
region <- make.region(region.name = "Survey Region", 
                      units = "m", 
                      shapefile = region.shapefile)
plot(region)
```

###2.2.2 Population
The second part of the simulation is the population description which needs a description of the population density.  For the investigation we will use a constant density over the whole surface.  Furthermore when the simulation later generates a population during the simulation it will do so using a known population size so the value of this constant is not important.  The _x.space_ and _y.space_ arguments describe the grid points on the density surface.  As the density surface will be the same everywhere this does not matter too much, however if the density surface varies then it may be wise to decrease the spacing between grid points to allow finer detail on the surface.  This code produces the density object and plots it over the region in Figure 4:
```{r density, fig.cap="Figure 4 - A plot of the study region with a heat map showing the population density overlayed", fig.align="center", fig.width = 7, fig.height = 3}
pop.density <- make.density(region = region, 
                            x.space = 1000, 
                            y.space = 1000, 
                            constant = 1) 
plot(pop.density, plot.units = "m", style = "blocks")
plot(region, add = TRUE)
```

Now that a description of the density across the region is available the population description can be put together from which the simulation will generate a population.  A fixed value for the population size, N=250, is given. We have chosen 250 because with the detection function we have used this results in around 60 observations, the minimum number of recomendations usually recommended for distance sampling surveys.  This will ensure that any effects of truncation distance are not obscured by using a large population size. If this is not given then DSsim will generate the population using the average density across the region.   
```{r population}
pop.description <- make.population.description(region.obj = region, 
                                               density.obj = pop.density, 
                                               N = 250, 
                                               fixed.N = TRUE)
```

###2.2.3 Defining Detectability
Next the components that will be used to simulate the observation process need to be made.  The first of these is the known detection function.  The key function can be one of _hn_(half normal) or _hr_(hazard rate).  Here a half normal with scale parameter 100 and a observation truncation distance of 500 is used:
```{r detection}
sigma = 100
detect <- make.detectability(key.function = "hn", 
                             scale.param = sigma, 
                             truncation = 500)
```

###2.2.4 Design
When carrying out a distance sampling survey we create a survey based on a design. Currently this cannot be done using DSsim and must be done using other software.  Here we have done this using the Distance for Windows software [@Thomas:2010cf].  A systematic parallel line transect design with a spacing of 1000m between transects was used.  The transects were orientated so that they were running across the narrower dimension of the study region, this resulted in 20 transects per survey. The recommended minimum number of transects for line transect studies is from 10-20 [@Buckland:2001vm].
```{r design}
parallel.design <- make.design(transect.type = "Line", 
                               design.details = c("Parallel","Systematic"), 
                               region.obj = region, 
                               path = "shapefiles")
```

###2.2.5 Analysis
Finally the simulation needs to know how to analyse the results of the observation process.  A list of models which can be fitted to the distance data will be made and the simulation will select the one with the minimum criteria value.  In the truncation distances investigation the simulation was forced to pick a half normal model.  The first truncation distance that was used was 1.25$\sigma$:
```{r analyses}
ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1)), 
                                       method = "ds", 
                                       truncation = 125)
```

###2.2.5.1 Model Selection
In the real world we do not know the shape of the detection function and must use model selection criteria to decide between models of different shape.  Here we use the AIC to decide between a hazard rate model and a half normal model but the BIC can also be used:
```{r analyses2}
ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "AIC", 
                                           truncation = 125)
```

###2.2.6 Simulations
Now that all of the components of the simulation have been made the simulation is made by putting them all together:
```{r make.sim}
simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses)
```

As simulations can take a long time to run it is often worth checking that the setup is right first.
The first thing that should be checked is that a population is being correctly generated within the region:
```{r gen.pop, fig.cap="Figure 5 - A plot of the study region with an example population displayed", fig.align="center", fig.width = 7, fig.height = 3}
pop <- generate.population(simtrunc125)
plot(region)
plot(pop)
```

Next it should be checked that the transects have been placed correctly:
```{r gen.transects, fig.cap="Figure 6 - A plot of the study region with an example set of transect lines overlayed", fig.align="center", fig.width = 7, fig.height = 3}
transects <- generate.transects(simtrunc125)
plot(region)
plot(transects, col = 4, lwd = 2)
```

The observation process can be quickly simulated once to ensure that it is working correctly.  The distance from each object to the transects will be used to calculate the probability of the object being detected.  Then Bernoulli trials with these probabilities of success are carried  out for each of the objects.  The observed objects are marked as blue points, the unobserved objects are the red points:
```{r survey, fig.cap="Figure 7 - A plot of the study region showing a completed observation process.  The red dots are the unobserved objects while the blue dots are the observed objects", fig.align="center", fig.width = 7, fig.height = 3}
eg.survey <- create.survey.results(simtrunc125)
plot(eg.survey)
```

This distance data can also be viewed in a histogram to get an idea of what the fitted detection function will look like:
```{r dist.data, fig.cap="Figure 8 - A histogram showing the distances from the transects at which objects were observed", fig.align="center", fig.width = 5, fig.height = 5}
dist.data <- get.distance.data(eg.survey)
hist(dist.data$distance, xlab = "Distance (m)", main = "Distance Data")
```

If the setup has been done right the simulation can now be run but first we will reset the seed so that subsequent simulations use the same population:
```{r first.sim, warning=FALSE, message=FALSE, eval=FALSE}
set.seed(4321)
simtrunc125 <- run(simtrunc125)
```

More simulations are then needed for the investigation; each using different truncation distances for the analysis.  After changing a part of the simulation it is necessary to make the simulation again to update it:

```{r sims, eval=FALSE}
Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1)), 
                                         method = "ds", truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResults.rda")
```


```{r model_selection_sims_not_run, echo=FALSE, eval=FALSE}
ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "AIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.aic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "AIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.aic)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsAIC.rda")

ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "BIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.bic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "BIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.bic)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsBIC.rda")

set.seed(4321)
region.shapefile <- read.shapefile("Study_ar") #DSsim assumes there is a shapefile called this in the R working directory
region <- make.region(region.name = "Survey Region", 
                      units = "m", 
                      shapefile = region.shapefile)
pop.density <- make.density(region = region, 
                            x.space = 1000, 
                            y.space = 1000, 
                            constant = 1)
pop.description <- make.population.description(region.obj = region, 
                                               density.obj = pop.density, 
                                               N = 250, 
                                               fixed.N = TRUE)
sigma = 120
shape = 3
detect <- make.detectability(key.function = "hr", 
                             scale.param = sigma, 
                             shape.param = shape,
                             truncation = 500)
parallel.design <- make.design(transect.type = "Line", 
                               design.details = c("Parallel","Systematic"), 
                               region.obj = region, 
                               path = "shapefiles")


ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "AIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.aic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims <- vector("list", length(Trun.dists))
sims[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.aic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "AIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.aic)
  sim  <- run(sim)
  sims[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsAIChrkey.rda")

ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                           method = "ds", 
                                           criteria = "BIC", 
                                           truncation = 125)

simtrunc125 <- make.simulation(reps = 999, 
                               single.transect.set = FALSE, 
                               region.obj = region, 
                               design.obj = parallel.design, 
                               population.description.obj = pop.description, 
                               detectability.obj = detect, 
                               ddf.analyses.list = ddf.analyses.bic)

set.seed(4321)
simtrunc125 <- run(simtrunc125)

Trun.dists <- c(1.25*sigma, 1.5*sigma, 1.75*sigma, 2*sigma, 2.5*sigma, 3*sigma)
sims.hr.bic <- vector("list", length(Trun.dists))
sims.hr.bic[[1]]<-simtrunc125
for(i in 2:6){
  set.seed(4321)
  ddf.analyses.bic <- make.ddf.analysis.list(dsmodel = list(~cds(key = "hn", formula = ~1), ~cds(key = "hr", formula = ~1)), 
                                             method = "ds", 
                                             criteria = "BIC", 
                                             truncation = Trun.dists[[i]])
  sim <- make.simulation(reps = 999, 
                         single.transect.set = FALSE, 
                         region.obj = region, 
                         design.obj = parallel.design, 
                         population.description.obj = pop.description, 
                         detectability.obj = detect, 
                         ddf.analyses.list = ddf.analyses.bic)
  sim  <- run(sim)
  sims.hr.bic[[i]]<-sim
}
save(sims, file = "~/GitHub/DSsim/DSsim/data/truncationResultsBIChrkey.rda")
```
Since these simulations take a long time to run we have run them in advance and saved the results as data in the DSsim package.  Each of these objects is a list of simulations with varying truncation distance.  We can use the following code to load these results:
```{r}
data("truncationResults")
data("truncationResultsAIC")
data("truncationResultsBIC")
data("truncationResultsAIChrkey")
data("truncationResultsBIChrkey")
```

##3. Extracting Result Statistics

The results of simulations can be viewed by calling *summary* on the simulation object:
```{r summary, eval=FALSE}
#Not run
summary(sims[[1]])
```

As this investigation involved running many simulations we provide a function to allow the automated extraction of results.  It is not necessary to understand how these functions work, details are provided here for interested readers however the reader could just run the code and skip to the next section if they prefer.

```{r}
extract.info <- function(simulation, info.name){
  switch(info.name,
         N = simulation@population.description@N,
         reps = simulation@reps,
         truncation.distance = simulation@ddf.analyses[[1]]@truncation,
         n = simulation@results$individuals$summary[1,4,1000],
         estimated.abundance = simulation@results$individuals$N[1,1,1000],
         mean.se = simulation@results$individuals$N[1,2,1000],
         percentage.bias = 100*((simulation@results$individuals$N[1,1,1000] 
                                 - simulation@population.description@N)
                                /simulation@population.description@N),
         RMSE = sqrt(sum((simulation@results$individuals$N[1,1,1:simulation@reps] 
                          - simulation@population.description@N)**2, na.rm = TRUE)/simulation@reps))
}
```

##4. The Results

Once the results have been extracted the function _kable_ from the package _knitr_ will be used to table the results:
```{r message=FALSE}
library(knitr)
```

Using the function _lapply_ the results from all of the simulations in  the list can be quickly extracted using the functions defined in Section 4:
```{r}
Trunc.Dist <- lapply(sims, extract.info, info.name = "truncation.distance")
n          <- lapply(sims, extract.info, info.name = "n")
Est.Abund  <- lapply(sims, extract.info, info.name = "estimated.abundance")
mean.se    <- lapply(sims, extract.info, info.name = "mean.se")
Perc.Bias  <- lapply(sims, extract.info, info.name = "percentage.bias")
RMSE.orig  <- lapply(sims, extract.info, info.name = "RMSE")
```

Then the results must be combined into a data frame to be tabled:
```{r}
simulation.data = cbind(Trunc.Dist = Trunc.Dist, 
                        n=n, 
                        Est.Abund = Est.Abund, 
                        mean.se = mean.se, 
                        Perc.Bias = Perc.Bias, 
                        RMSE=RMSE.orig)
```


Finally the results can be tabled.  The align argument has been used  to centre the results in each column and the digits argument has been used to specify the number of decimal places in each column. 
```{r results="asis", fig.cap = "Table 1 - The results from the simulations"}
table<-kable(simulation.data, 
             digits = 2, 
             col.names = c("$Trunc Dist$", "$n$", "$Mean \\hat{N}$", "$SE$", "$\\% Bias$", "$RMSE$"),
             align = c('c', 'c', 'c', 'c', 'c', 'c', 'c') )

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Results", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```

```{r echo=FALSE}
#NEED TO ADD MODEL SELECTION CRITERIA
Trunc.Dist.aic <- lapply(sims.aic, extract.info, info.name = "truncation.distance")
n.aic          <- lapply(sims.aic, extract.info, info.name = "n")
Est.Abund.aic  <- lapply(sims.aic, extract.info, info.name = "estimated.abundance")
mean.se.aic    <- lapply(sims.aic, extract.info, info.name = "mean.se")
Perc.Bias.aic  <- lapply(sims.aic, extract.info, info.name = "percentage.bias")
RMSE.aic       <- lapply(sims.aic, extract.info, info.name = "RMSE")

Trunc.Dist.bic <- lapply(sims.bic, extract.info, info.name = "truncation.distance")
n.bic          <- lapply(sims.bic, extract.info, info.name = "n")
Est.Abund.bic  <- lapply(sims.bic, extract.info, info.name = "estimated.abundance")
mean.se.bic    <- lapply(sims.bic, extract.info, info.name = "mean.se")
Perc.Bias.bic  <- lapply(sims.bic, extract.info, info.name = "percentage.bias")
RMSE.bic       <- lapply(sims.bic, extract.info, info.name = "RMSE")

Trunc.Dist <- c(Trunc.Dist.aic, Trunc.Dist.bic)
n          <- c(n.aic, n.bic)
Est.Abund  <- c(Est.Abund.aic, Est.Abund.bic)
mean.se    <- c(mean.se.aic, mean.se.bic)
Perc.Bias  <- c(Perc.Bias.aic, Perc.Bias.bic)
RMSE       <- c(RMSE.aic, RMSE.bic)
```

```{r echo = FALSE}
simulation.modelselect.data = cbind(Trunc.Dist = Trunc.Dist, 
                                    n=n,
                                    Est.Abund = Est.Abund,
                                    mean.se = mean.se, 
                                    Perc.Bias = Perc.Bias, 
                                    RMSE=RMSE)
```

```{r results="asis", fig.cap = "Table 2 - The results from the model selection simulations", echo = FALSE}
table<-kable(simulation.data, 
             digits = 2, 
             col.names = c("$Trunc Dist$", "$n$", "$Mean \\hat{N}$", "$SE$", "$\\% Bias$", "$RMSE$"),
             align = c('c', 'c', 'c', 'c', 'c', 'c', 'c') )

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Results", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```

```{r echo=FALSE}
#NEEDS MODEL SELECTION CRITERIA
Trunc.Dist.hr.aic <- lapply(sims.hr.aic, extract.info, info.name = "truncation.distance")
n.hr.aic          <- lapply(sims.hr.aic, extract.info, info.name = "n")
Est.Abund.hr.aic  <- lapply(sims.hr.aic, extract.info, info.name = "estimated.abundance")
mean.se.hr.aic    <- lapply(sims.hr.aic, extract.info, info.name = "mean.se")
Perc.Bias.hr.aic  <- lapply(sims.hr.aic, extract.info, info.name = "percentage.bias")
RMSE.hr.aic       <- lapply(sims.hr.aic, extract.info, info.name = "RMSE")

Trunc.Dist.hr.bic <- lapply(sims.hr.bic, extract.info, info.name = "truncation.distance")
n.hr.bic          <- lapply(sims.hr.bic, extract.info, info.name = "n")
Est.Abund.hr.bic  <- lapply(sims.hr.bic, extract.info, info.name = "estimated.abundance")
mean.se.hr.bic    <- lapply(sims.hr.bic, extract.info, info.name = "mean.se")
Perc.Bias.hr.bic  <- lapply(sims.hr.bic, extract.info, info.name = "percentage.bias")
RMSE.hr.bic       <- lapply(sims.hr.bic, extract.info, info.name = "RMSE")

Trunc.Dist <- c(Trunc.Dist.hr.aic, Trunc.Dist.hr.bic)
n          <- c(n.hr.aic, n.hr.bic)
Est.Abund  <- c(Est.Abund.hr.aic, Est.Abund.hr.bic)
mean.se    <- c(mean.se.hr.aic, mean.se.hr.bic)
Perc.Bias  <- c(Perc.Bias.hr.aic, Perc.Bias.hr.bic)
RMSE       <- c(RMSE.hr.aic, RMSE.hr.bic)
```

```{r echo = FALSE}
simulation.modelselect.hr.data = cbind(Trunc.Dist = Trunc.Dist, 
                                       n=n, 
                                       Est.Abund = Est.Abund, 
                                       mean.se = mean.se, 
                                       Perc.Bias = Perc.Bias, 
                                       RMSE=RMSE)
```

```{r results="asis", fig.cap = "Table 3 - The results from the model selection simulations when the true detection function has a hazard rate key", echo = FALSE}
table<-kable(simulation.modelselect.hr.data, 
             digits = 2, 
             col.names = c("$Trunc Dist$", "$n$", "$Mean \\hat{N}$", "$SE$", "$\\% Bias$", "$RMSE$"),
             align = c('c', 'c', 'c', 'c', 'c', 'c', 'c') )

print(table, floating=TRUE, NA.string="NA", caption = "Simulation Results", caption.placement="top", table.placement="!h", latex.environments="center", type = "html")
```

For distance sampling surveys it is usually recommended to have a minimum of 60-80 detections[@Buckland:2001vm] however even at this small number of observations $\% Bias$ is small.  Increasing the truncation distance does seem to have increased this bias slightly however there is clearly a trend in RMSE which shows that the increase in precision, which can be seen in the standard error, greatly outweighs this effect:
```{r fig.cap = "Figure 9 - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5}
plot(Trunc.Dist[1:6], RMSE.orig)
```

```{r fig.cap = "Figure 9b - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.aic)
```

```{r fig.cap = "Figure 9c - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.bic)
```

```{r fig.cap = "Figure 9d - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.hr.aic)
```

```{r fig.cap = "Figure 9e - There is a clear downwards trend in RMSE as less data is truncated", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
plot(Trunc.Dist[1:6], RMSE.hr.bic)
```

```{r fig.cap = "Figure 10 - The red line indicates the true size of the population while the blue dots are the means of the estimates.  There is no clear trend in the accuracy of the estimate however it is easy to see that the precision improves considerably when less data is truncated", fig.align="center", fig.width = 5, fig.height = 5}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims[[1]]@results$individuals$N[1,1,1:999], sims[[2]]@results$individuals$N[1,1,1:999], sims[[3]]@results$individuals$N[1,1,1:999], sims[[4]]@results$individuals$N[1,1,1:999], sims[[5]]@results$individuals$N[1,1,1:999], sims[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 11", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.aic[[1]]@results$individuals$N[1,1,1:999], sims.aic[[2]]@results$individuals$N[1,1,1:999], sims.aic[[3]]@results$individuals$N[1,1,1:999], sims.aic[[4]]@results$individuals$N[1,1,1:999], sims.aic[[5]]@results$individuals$N[1,1,1:999], sims.aic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 12", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.bic[[1]]@results$individuals$N[1,1,1:999], sims.bic[[2]]@results$individuals$N[1,1,1:999], sims.bic[[3]]@results$individuals$N[1,1,1:999], sims.bic[[4]]@results$individuals$N[1,1,1:999], sims.bic[[5]]@results$individuals$N[1,1,1:999], sims.bic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 13", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.hr.aic[[1]]@results$individuals$N[1,1,1:999], sims.hr.aic[[2]]@results$individuals$N[1,1,1:999], sims.hr.aic[[3]]@results$individuals$N[1,1,1:999], sims.hr.aic[[4]]@results$individuals$N[1,1,1:999], sims.hr.aic[[5]]@results$individuals$N[1,1,1:999], sims.hr.aic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```

```{r fig.cap = "Figure 14", fig.align="center", fig.width = 5, fig.height = 5, echo=FALSE}
library(ggplot2)
data = data.frame(Truncation = factor(rep(c(125, 150, 175, 200, 250, 300), each=999)), Estimates = c(sims.hr.bic[[1]]@results$individuals$N[1,1,1:999], sims.hr.bic[[2]]@results$individuals$N[1,1,1:999], sims.hr.bic[[3]]@results$individuals$N[1,1,1:999], sims.hr.bic[[4]]@results$individuals$N[1,1,1:999], sims.hr.bic[[5]]@results$individuals$N[1,1,1:999], sims.hr.bic[[6]]@results$individuals$N[1,1,1:999]))

ggplot(data, aes(x = Truncation, y = Estimates)) + geom_boxplot() + geom_hline(yintercept = 250, color = "red", size = 0.5) + stat_summary(fun.y = mean, geom="point", size = 2, color = "blue")
```
##5. The Conclusions

Changing the truncation distance did not lead to big differences in the % Bias however there was a clear trend in precision.  Since each simulation was successfully run the same number of times we could use the RMSE as a meaningful comparison to combine the two and found that truncating less data was better by this metric.  However, differences were small even at this small sample size and so truncation distance should not be a big concern at the analysis stage.  It should also be noted that the observers for the survey should not be given a truncation distance because if they see something just beyond this distance they may be tempted to record it at the truncation distance which will lead to heaping at this distance. 

##6. References



